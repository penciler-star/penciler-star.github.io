[ { "title": "GPU学习（一）", "url": "/posts/post20230427/", "categories": "编程", "tags": "GPU", "date": "2023-04-27 05:38:02 +0000", "snippet": "一、简介GPU是图形处理器（Graphics Processing Unit）的缩写，它是一种专门设计用来加速图形渲染的处理器，其内部的线程众多，这些线程能够并行处理数据，因此能够应用于机器学习、视频编辑和游戏渲染等场景。GPU分为两种类型：集成和独立。集成GPU嵌入在CPU旁边。而独立GPU是一块单独的芯片，通常需要通过主板上的PCI Express进行连接。注：本篇的参考学习网站为：Re...", "content": "一、简介GPU是图形处理器（Graphics Processing Unit）的缩写，它是一种专门设计用来加速图形渲染的处理器，其内部的线程众多，这些线程能够并行处理数据，因此能够应用于机器学习、视频编辑和游戏渲染等场景。GPU分为两种类型：集成和独立。集成GPU嵌入在CPU旁边。而独立GPU是一块单独的芯片，通常需要通过主板上的PCI Express进行连接。注：本篇的参考学习网站为：Render Hell – BookGraphic Card Components二、显卡的外围电路一块完整的显卡除了GPU芯片外，还包括显存、随机存取存储器数字模拟转换器、主板接口、视频接口、散热器（散热片、风扇）等硬件，驱动程序软件等软件。下面将逐一进行介绍。1、显存显存（VRAM）是视频随机存取存储器（Video Random Access Memory）的缩写，是一种特殊的DRAM，通常用来存储顶点和纹理数据。渲染图像时，CPU从HDD或SSD中读取顶点和纹理数据到RAM中，然后数据从RAM再传到VRAM中。（RAM中的数据除非不再需要，否则一般选择保留顶点数据）2、RAMDACRAMDAC是随机存取存储器数字模拟转换器（Random Access Memory Digital-to-Analog Converter）的缩写。它是一种单芯片，用于将数字编码的图像转换为模拟信号，以便显示器能够显示。RAMDAC实际上由四个不同的部件组成：用于存储颜色映射的SRAM和三个数字模拟转换器（DAC），分别对应显示器的红、绿、蓝电子枪。（SRAM是静态随机存取存储器（Static Random Access Memory）的缩写，它比DRAM更快但更贵，通常用作缓存）3、主板接口主板接口通常是PCI Express接口，是GPU与CPU的连接总线，负责传输指令和数据。4、视频接口显卡通常包括多种接口，用于连接显示器和其他设备。常见的接口类型包括VGA、DVI、HDMI、DisplayPort、USB-C和Thunderbolt等。 VGA（Video Graphics Array）接口是一种模拟接口，主要用于连接CRT显示器，其成本低廉、易于获取。 DVI（Digital Visual Interface）接口可以传输模拟和数字信号，支持高分辨率显示器，但不支持传输音频。 HDMI（High-Definition Multimedia Interface）接口是一种数字接口，支持高清视频和音频信号传输，支持加密，但传输距离通常不超过35米或10米。 DisplayPort接口是一种数字接口，支持高分辨率显示器和多显示器设置。 USB-C接口不仅支持上述所有功能，还可以提供快速充电，也可以通过适配器与HDMI、VGA和DisplayPort接口兼容。 Thunderbolt接口与USB-C接口类似，其将PCI Express和DisplayPort两种串行信号结合在一起，并提供直流电源，最多可以支持六个外设。选择哪种接口取决于成本需求和显示器的兼容性等。5、显卡驱动程序显卡驱动程序是一种软件，它为显卡提供操作指令，使显卡能够在计算机上渲染图像。编写显卡驱动程序需要深入了解计算机硬件和软件，以及操作系统和编程语言。通常情况下，显卡驱动程序由显卡制造商（如英特尔、英伟达和AMD）提供，并且会定期更新以修复错误和提高性能。三、GPU芯片GPU芯片是显卡的核心部件，它负责执行计算任务。1、片上缓存片上缓存（on-chip Cache）置于GPU内部，分为一级和二级。一级缓存运行更快，但空间只有几百KB；二级缓存运行慢，但空间有几MB。显存中的数据要先读到二级缓存，然后再到一级缓存。2、GPU寄存器堆寄存器堆（register file）用于存放将要处理的数据。其访问速度最快，但是容量较小。以目前最新的Ampere架构的GA102为例，每个SM上的寄存器总量256KB，使用时被均分为了4块，且该寄存器块的64KB空间需要被warp中线程平均分配，所以在线程多的情况下，每个线程拿到的寄存器空间相当小。通常来说，一级缓存的数据需要先放入GPU寄存器堆，最后才能进入GPU内核进行运算。3、GPU运算核心GPU运算核心通常包括： GTE（Giga Thread Engine）负责将线程块Block分配给SM，并管理所有正在进行的工作。 SM（Streaming Multiprocessors，流多处理器）负责执行Block。SM是一种单指令多线程（SIMT）架构的处理器，类似于单指令流多数据流（SIMD）的特点，包括指令发射单元、若干个流处理器（streamingProcessor，sp）或标量处理器（Scalarproeessor，SP）、特殊函数处理器（speeial Funetion Proeessor，SFU）、可快速访问的共享存储器（shared memory）以及指令和常量（constant）缓存。 MC（Memory Controller）内存控制器，负责访问显存。 四、设置全局变量在图形渲染管线之前，还需经历如下步骤（主要是CPU与GPU的通信）：1、设置Render StateRender State 是网格渲染方式的一种全局定义，它包含如下信息：顶点、像素着色器、纹理、材质、光照、透明度等。2、绘图调用此命令是CPU告诉GPU，绘制哪些东西，是一个命令。这些命令通常会由CPU发送至GPU的命令缓冲区。五、图形渲染管线图形渲染流水线（Graphics Pipeline）是指GPU在渲染帧时数据输入和输出的操作流程。给定流水线状态和输入，GPU执行一系列操作来创建最终图像。在完成上述步骤后，进行经典的图形渲染管线：1、接受顶点将顶点数据先从RAM传输到VRAM，再从VRAM传输到缓存中。2、顶点转换将顶点从模型空间转换到世界空间，然后再转换到相机空间。3、顶点插值赋予每个顶点属性，例如颜色、法线等。4、创建三角形将顶点组成三角形面片。5、创建fragment这一步也成为光栅化（rasterization），将图元转为带有颜色和深度值的像素。6、着色将像素进行着色。7、输出到帧缓存将着色后的像素放置在帧缓存（Frame Buffer）中。8、显示把帧缓存中的图像显示在屏幕上。" }, { "title": "Linux驱动学习（二）", "url": "/posts/post20230426/", "categories": "编程", "tags": "Linux", "date": "2023-04-26 05:38:02 +0000", "snippet": "一、前言续前章：Linux驱动学习（一）学习参考网址：https://embetronicx.com/tutorials/linux/二、创建/dev/目录下的文件在使用insmod加载驱动后，应创建设备文件，以便系统能够访问此设备。linux设备文件都存放在/dev/目录下。例如：crw--w---- 1 root tty 4, 0 Aug 15 10:40 tty0brw-rw---- ...", "content": "一、前言续前章：Linux驱动学习（一）学习参考网址：https://embetronicx.com/tutorials/linux/二、创建/dev/目录下的文件在使用insmod加载驱动后，应创建设备文件，以便系统能够访问此设备。linux设备文件都存放在/dev/目录下。例如：crw--w---- 1 root tty 4, 0 Aug 15 10:40 tty0brw-rw---- 1 root disk 1, 0 Aug 15 10:40 ram01、手动创建设备文件可以通过mknod手动创建设备文件：mknod -m &lt;permissions&gt; &lt;name&gt; &lt;device type&gt; &lt;major&gt; &lt;minor&gt;-m &lt;permissions&gt; – optional argument that sets the permission bits of the new device file to permissions&lt;name&gt; – your device file name that should have a full path (/dev/name)&lt;device* type&gt;* – Put **c or b​\t\tc – Character Device​\t\tb – Block Device&lt;major&gt; – major number of your driver&lt;minor&gt; – minor number of your driver举个例子：sudo mknod -m 666 /dev/etx_device c 246 0可以通过rmmod进行删除设备文件2、自动创建设备文件例程：create_file.c#include &lt;linux/kernel.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/kdev_t.h&gt;#include &lt;linux/fs.h&gt;#include &lt;linux/err.h&gt;#include &lt;linux/device.h&gt;dev_t dev = 0;static struct class *dev_class;/*Module init function*/static int __init hello_world_init(void){ /*Automatically allocating Major number*/ if((alloc_chrdev_region(&amp;dev, 0, 1, \"new_Dev\")) &lt;0){ pr_err(\"Cannot allocate major number for device\\n\"); return -1; } pr_info(\"Major = %d Minor = %d \\n\",MAJOR(dev), MINOR(dev)); /*Creating struct class*/ dev_class = class_create(THIS_MODULE,\"new_class\"); if(IS_ERR(dev_class)){ pr_err(\"Cannot create the struct class for device\\n\"); goto r_class; } /*Creating device*/ if(IS_ERR(device_create(dev_class,NULL,dev,NULL,\"new_device\"))){ pr_err(\"Cannot create the Device\\n\"); goto r_device; } pr_info(\"Kernel Module Inserted Successfully...\\n\"); return 0;r_device: class_destroy(dev_class);r_class: unregister_chrdev_region(dev,1); return -1;}/*Module exit function*/static void __exit hello_world_exit(void){ device_destroy(dev_class,dev); class_destroy(dev_class); unregister_chrdev_region(dev, 1); pr_info(\"Kernel Module Removed Successfully...\\n\");}module_init(hello_world_init);module_exit(hello_world_exit);MODULE_LICENSE(\"GPL\");MODULE_AUTHOR(\"Author\");MODULE_DESCRIPTION(\"Automatically Creating a Device file\");MODULE_VERSION(\"1:1.0\");进行make，然后insmod命令即可。三、操作设备文件创建设备文件后，用户需要操作这个文件，与设备进行通信。那在这个文件中，就需要定义一组可以被调用的函数，完成通信任务。例程：#include &lt;linux/kernel.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/kdev_t.h&gt;#include &lt;linux/fs.h&gt;#include &lt;linux/err.h&gt;#include &lt;linux/cdev.h&gt;#include &lt;linux/device.h&gt;dev_t dev = 0;static struct class *dev_class;static struct cdev etx_cdev;/*** Function Prototypes*/static int __init etx_driver_init(void);static void __exit etx_driver_exit(void);static int etx_open(struct inode *inode, struct file *file);static int etx_release(struct inode *inode, struct file *file);static ssize_t etx_read(struct file *filp, char __user *buf, size_t len,loff_t * off);static ssize_t etx_write(struct file *filp, const char *buf, size_t len, loff_t * off);static struct file_operations fops ={ .owner = THIS_MODULE, .read = etx_read, .write = etx_write, .open = etx_open, .release = etx_release,};/*** This function will be called when we open the Device file*/static int etx_open(struct inode *inode, struct file *file){ pr_info(\"Driver Open Function Called...!!!\\n\"); return 0;}/*** This function will be called when we close the Device file*/static int etx_release(struct inode *inode, struct file *file){ pr_info(\"Driver Release Function Called...!!!\\n\"); return 0;}/*** This function will be called when we read the Device file*/static ssize_t etx_read(struct file *filp, char __user *buf, size_t len, loff_t *off){ pr_info(\"Driver Read Function Called...!!!\\n\"); return 0;}/*** This function will be called when we write the Device file*/static ssize_t etx_write(struct file *filp, const char __user *buf, size_t len, loff_t *off){ pr_info(\"Driver Write Function Called...!!!\\n\"); return len;}/*** Module Init function*/static int __init etx_driver_init(void){ /*Allocating Major number*/ if((alloc_chrdev_region(&amp;dev, 0, 1, \"operate_Dev\")) &lt;0){ pr_err(\"Cannot allocate major number\\n\"); return -1; } pr_info(\"Major = %d Minor = %d \\n\",MAJOR(dev), MINOR(dev)); /*Creating cdev structure*/ cdev_init(&amp;etx_cdev,&amp;fops); /*Adding character device to the system*/ if((cdev_add(&amp;etx_cdev,dev,1)) &lt; 0){ pr_err(\"Cannot add the device to the system\\n\"); goto r_class; } /*Creating struct class*/ if(IS_ERR(dev_class = class_create(THIS_MODULE,\"operate_class\"))){ pr_err(\"Cannot create the struct class\\n\"); goto r_class; } /*Creating device*/ if(IS_ERR(device_create(dev_class,NULL,dev,NULL,\"operate_device\"))){ pr_err(\"Cannot create the Device 1\\n\"); goto r_device; } pr_info(\"Device Driver Insert...Done!!!\\n\"); return 0;r_device: class_destroy(dev_class);r_class: unregister_chrdev_region(dev,1); return -1;}/*** Module exit function*/static void __exit etx_driver_exit(void){ device_destroy(dev_class,dev); class_destroy(dev_class); cdev_del(&amp;etx_cdev); unregister_chrdev_region(dev, 1); pr_info(\"Device Driver Remove...Done!!!\\n\");}module_init(etx_driver_init);module_exit(etx_driver_exit);MODULE_LICENSE(\"GPL\");MODULE_AUTHOR(\"Author\");MODULE_DESCRIPTION(\"File Operations\");MODULE_VERSION(\"1:1.3\");写makefile文件：obj-m += operate_driver.oKDIR = /lib/modules/$(shell uname -r)/buildall: make -C $(KDIR) M=$(shell pwd) modules clean: make -C $(KDIR) M=$(shell pwd) cleanload驱动文件：sudo insmod然后可以通过如下命令和刚刚写好的驱动程序进行通信：sudo suecho 1 &gt; /dev/operate_device四、实际创建一个可以读写的虚拟驱动在完成上述所有步骤后，我们可以尝试自己创建一个驱动程序，此程序能够完成与用户态程序的通信，例如读写、打开关闭等操作。在进行块数据的传输时，需要实现分配空间，并在用户态、内核态之间来回拷贝。例如使用如下函数完成上述功能：#include &lt;linux/slab.h&gt;#include&lt;linux/uaccess.h&gt;void *kmalloc(size_t size, gfp_t flags);void kfree(const void *objp)unsigned long copy_from_user(void *to, const void __user *from, unsigned long n);unsigned long copy_to_user(const void __user *to, const void *from, unsigned long n);我们利用如上函数，完成驱动程序：real_driver.c#include &lt;linux/kernel.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/kdev_t.h&gt;#include &lt;linux/fs.h&gt;#include &lt;linux/cdev.h&gt;#include &lt;linux/device.h&gt;#include&lt;linux/slab.h&gt; //kmalloc()#include&lt;linux/uaccess.h&gt; //copy_to/from_user()#include &lt;linux/err.h&gt;#define mem_size 1024 //Memory Sizedev_t dev = 0;static struct class *dev_class;static struct cdev etx_cdev;uint8_t *kernel_buffer;/*** Function Prototypes*/static int __init etx_driver_init(void);static void __exit etx_driver_exit(void);static int etx_open(struct inode *inode, struct file *file);static int etx_release(struct inode *inode, struct file *file);static ssize_t etx_read(struct file *filp, char __user *buf, size_t len,loff_t * off);static ssize_t etx_write(struct file *filp, const char *buf, size_t len, loff_t * off);/*** File Operations structure*/static struct file_operations fops ={ .owner = THIS_MODULE, .read = etx_read, .write = etx_write, .open = etx_open, .release = etx_release,}; /*** This function will be called when we open the Device file*/static int etx_open(struct inode *inode, struct file *file){ pr_info(\"Device File Opened...!!!\\n\"); return 0;}/*** This function will be called when we close the Device file*/static int etx_release(struct inode *inode, struct file *file){ pr_info(\"Device File Closed...!!!\\n\"); return 0;}/*** This function will be called when we read the Device file*/static ssize_t etx_read(struct file *filp, char __user *buf, size_t len, loff_t *off){ //Copy the data from the kernel space to the user-space if( copy_to_user(buf, kernel_buffer, mem_size) ) { pr_err(\"Data Read : Err!\\n\"); } pr_info(\"Data Read : Done!\\n\"); return mem_size;}/*** This function will be called when we write the Device file*/static ssize_t etx_write(struct file *filp, const char __user *buf, size_t len, loff_t *off){ //Copy the data to kernel space from the user-space if( copy_from_user(kernel_buffer, buf, len) ) { pr_err(\"Data Write : Err!\\n\"); } pr_info(\"Data Write : Done!\\n\"); return len;}/*** Module Init function*/static int __init etx_driver_init(void){ /*Allocating Major number*/ if((alloc_chrdev_region(&amp;dev, 0, 1, \"real_driver_Dev\")) &lt;0){ pr_info(\"Cannot allocate major number\\n\"); return -1; } pr_info(\"Major = %d Minor = %d \\n\",MAJOR(dev), MINOR(dev)); /*Creating cdev structure*/ cdev_init(&amp;etx_cdev,&amp;fops); /*Adding character device to the system*/ if((cdev_add(&amp;etx_cdev,dev,1)) &lt; 0){ pr_info(\"Cannot add the device to the system\\n\"); goto r_class; } /*Creating struct class*/ if(IS_ERR(dev_class = class_create(THIS_MODULE,\"real_driver_class\"))){ pr_info(\"Cannot create the struct class\\n\"); goto r_class; } /*Creating device*/ if(IS_ERR(device_create(dev_class,NULL,dev,NULL,\"real_driver_device\"))){ pr_info(\"Cannot create the Device 1\\n\"); goto r_device; } /*Creating Physical memory*/ if((kernel_buffer = kmalloc(mem_size , GFP_KERNEL)) == 0){ pr_info(\"Cannot allocate memory in kernel\\n\"); goto r_device; } strcpy(kernel_buffer, \"Hello_World\"); pr_info(\"Device Driver Insert...Done!!!\\n\"); return 0; r_device: class_destroy(dev_class);r_class: unregister_chrdev_region(dev,1); return -1;}/*** Module exit function*/static void __exit etx_driver_exit(void){ kfree(kernel_buffer); device_destroy(dev_class,dev); class_destroy(dev_class); cdev_del(&amp;etx_cdev); unregister_chrdev_region(dev, 1); pr_info(\"Device Driver Remove...Done!!!\\n\");}module_init(etx_driver_init);module_exit(etx_driver_exit);MODULE_LICENSE(\"GPL\");MODULE_AUTHOR(\"Author\");MODULE_DESCRIPTION(\"Real Linux Device Driver\");MODULE_VERSION(\"1:1.4\");编写Makefile：obj-m += real_driver.o KDIR = /lib/modules/$(shell uname -r)/build all:\tmake -C $(KDIR) M=$(shell pwd) modules clean:\tmake -C $(KDIR) M=$(shell pwd) clean随后利用如下命令进行load：sudo insmod real_driver.ko完成后，在用户空间编写如下C语言程序：test.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;int8_t write_buf[1024];int8_t read_buf[1024];int main(){ int fd; char option; printf(\"*********************************\\n\"); fd = open(\"/dev/real_driver_device\", O_RDWR); if(fd &lt; 0) { printf(\"Cannot open device file...\\n\"); return 0; } while(1) { printf(\"****Please Enter the Option******\\n\"); printf(\" 1. Write \\n\"); printf(\" 2. Read \\n\"); printf(\" 3. Exit \\n\"); printf(\"*********************************\\n\"); scanf(\" %c\", &amp;option); printf(\"Your Option = %c\\n\", option); switch(option) { case '1': printf(\"Enter the string to write into driver :\"); scanf(\" %[^\\t\\n]s\", write_buf); printf(\"Data Writing ...\"); write(fd, write_buf, strlen(write_buf)+1); printf(\"Done!\\n\"); break; case '2': printf(\"Data Reading ...\"); read(fd, read_buf, 1024); printf(\"Done!\\n\\n\"); printf(\"Data = %s\\n\\n\", read_buf); break; case '3': close(fd); exit(1); break; default: printf(\"Enter Valid option = %c\\n\",option); break; } } close(fd);}随后进行编译：gcc -o test test.c运行test程序，即可查看结果。卸载时，需要输入：sudu rmmod read_driver" }, { "title": "Linux驱动学习（一）", "url": "/posts/post20230422/", "categories": "编程", "tags": "Linux", "date": "2023-04-22 03:43:02 +0000", "snippet": "一、前言驱动程序是外界硬件设备、操作系统、用户之间通信的桥梁。驱动程序基本上都是使用C语言完成，且处于内核空间。现代Linux驱动程序基本都支持动态装载。硬件设备主要分为：字符设备、块设备、网络设备，其驱动程序略有差别。学习参考网址：https://embetronicx.com/tutorials/linux/二、第一个驱动程序首先编写如下C程序。hello_world.c#include...", "content": "一、前言驱动程序是外界硬件设备、操作系统、用户之间通信的桥梁。驱动程序基本上都是使用C语言完成，且处于内核空间。现代Linux驱动程序基本都支持动态装载。硬件设备主要分为：字符设备、块设备、网络设备，其驱动程序略有差别。学习参考网址：https://embetronicx.com/tutorials/linux/二、第一个驱动程序首先编写如下C程序。hello_world.c#include&lt;linux/kernel.h&gt;#include&lt;linux/init.h&gt;#include&lt;linux/module.h&gt;/*** Module Init function*/static int __init hello_world_init(void){ printk(KERN_INFO \"Welcome to EmbeTronicX\\n\"); printk(KERN_INFO \"This is the Simple Module\\n\"); printk(KERN_INFO \"Kernel Module Inserted Successfully...\\n\"); return 0;}/*** Module Exit function*/static void __exit hello_world_exit(void){ printk(KERN_INFO \"Kernel Module Removed Successfully...\\n\");}module_init(hello_world_init);module_exit(hello_world_exit);MODULE_LICENSE(\"GPL\");MODULE_AUTHOR(\"author\");MODULE_DESCRIPTION(\"Hello world driver\");MODULE_VERSION(\"1:1.0\");然后进行编译：obj-m += hello_world.oKDIR = /lib/modules/$(shell uname -r)/buildall: make -C $(KDIR) M=$(shell pwd) modulesclean: make -C $(KDIR) M=$(shell pwd) clean随后进行驱动程序的加载：sudo insmod hello_world_module.ko查看驱动详细信息：modinfo hello_world_module.ko卸载：sudo rmmod hello_world_module三、传递参数在驱动程序中，如果需要进行参数的定义，不仅要先像C语言一样声明变量、赋值等，还需要用到如下一些函数进行初始化或回调，如：module_param() //定义一个变量module_param_array() //定义一个数组module_param_cb() //如果变量被更改之后进行回调例程为：hello_world.c#include&lt;linux/kernel.h&gt;#include&lt;linux/init.h&gt;#include&lt;linux/module.h&gt;#include&lt;linux/moduleparam.h&gt; int valueETX, arr_valueETX[4];char *nameETX;int cb_valueETX = 0; module_param(valueETX, int, S_IRUSR|S_IWUSR); //integer valuemodule_param(nameETX, charp, S_IRUSR|S_IWUSR); //Stringmodule_param_array(arr_valueETX, int, NULL, S_IRUSR|S_IWUSR); //Array of integers /*----------------------Module_param_cb()--------------------------------*/int notify_param(const char *val, const struct kernel_param *kp){ int res = param_set_int(val, kp); // Use helper for write variable if(res==0) { printk(KERN_INFO \"Call back function called...\\n\"); printk(KERN_INFO \"New value of cb_valueETX = %d\\n\", cb_valueETX); return 0; } return -1;} const struct kernel_param_ops my_param_ops = { .set = &amp;notify_param, // Use our setter ... .get = &amp;param_get_int, // .. and standard getter}; module_param_cb(cb_valueETX, &amp;my_param_ops, &amp;cb_valueETX, S_IRUGO|S_IWUSR );/*-------------------------------------------------------------------------*//*** Module init function*/static int __init hello_world_init(void){ int i; printk(KERN_INFO \"ValueETX = %d \\n\", valueETX); printk(KERN_INFO \"cb_valueETX = %d \\n\", cb_valueETX); printk(KERN_INFO \"NameETX = %s \\n\", nameETX); for (i = 0; i &lt; (sizeof arr_valueETX / sizeof (int)); i++) { printk(KERN_INFO \"Arr_value[%d] = %d\\n\", i, arr_valueETX[i]); } printk(KERN_INFO \"Kernel Module Inserted Successfully...\\n\"); return 0;}/*** Module Exit function*/static void __exit hello_world_exit(void){ printk(KERN_INFO \"Kernel Module Removed Successfully...\\n\");} module_init(hello_world_init);module_exit(hello_world_exit); MODULE_LICENSE(\"GPL\");MODULE_AUTHOR(\"Author\");MODULE_DESCRIPTION(\"Passing parameters to my driver\");MODULE_VERSION(\"1.0\");然后进行编译：obj-m += hello_world_module.oKDIR = /lib/modules/$(shell uname -r)/buildall: make -C $(KDIR) M=$(shell pwd) modulesclean: make -C $(KDIR) M=$(shell pwd) clean并在之后进行驱动程序的加载和变量初始化赋值：sudo insmod hello_world_module.ko valueETX=14 nameETX=\"EmbeTronicX\" arr_valueETX=100,102,104,106此时如果需要更改变量值，则需要输入如下命令：sudo sh -c \"echo 13 &gt; /sys/module/hello_world_module/parameters/cb_valueETX\"因为我们定义了回到回调函数notify_param()，所以可以得到输出：Call back function called...New value of cb_valueETX = 13最后进行驱动程序的卸载：sudo rmmod hello_world_module四、设备驱动程序的主次数字主数字和次数字：Major Number and Minor Number主数字代表什么类型的设备，次数字代表设备号。其可分为静态分配和动态分配两种方式：静态分配：如定义一个主数字为235，次数字为0的设备。要求的连续设备编号的总数为1。设备描述为MY_Dev。//函数原型int register_chrdev_region(dev_t first, unsigned int count, char *name);//成功返回0//下面是一个例子dev_t dev = MKDEV(235, 0);register_chrdev_region(dev, 1, \"MY_Dev\");动态分配：//函数原型int alloc_chrdev_region(dev_t *dev, unsigned int firstminor, unsigned int count, char *name);由于我们基本上不需要事先了解主数字编号，故通常使用动态分配，这将由系统自动进行分配。释放：void unregister_chrdev_region(dev_t first, unsigned int count);静态分配的例程如下：hello_major_minor_static.c#include&lt;linux/kernel.h&gt;#include&lt;linux/init.h&gt;#include&lt;linux/module.h&gt;#include &lt;linux/fs.h&gt;//creating the dev with our custom major and minor numberdev_t dev = MKDEV(235, 0);/*** Module Init function*/static int __init hello_world_init(void){ register_chrdev_region(dev, 1, \"MY_Dev\"); printk(KERN_INFO \"Major = %d Minor = %d \\n\",MAJOR(dev), MINOR(dev)); printk(KERN_INFO \"Kernel Module Inserted Successfully...\\n\"); return 0;}/*** Module exit function*/static void __exit hello_world_exit(void){ unregister_chrdev_region(dev, 1); printk(KERN_INFO \"Kernel Module Removed Successfully...\\n\");} module_init(hello_world_init);module_exit(hello_world_exit); MODULE_LICENSE(\"GPL\");MODULE_AUTHOR(\"Autuor\");MODULE_DESCRIPTION(\"Major and Minor number test static\");MODULE_VERSION(\"1:1.0\");动态分配的例程如下：hello_major_minor_dynamic.c#include&lt;linux/kernel.h&gt;#include&lt;linux/init.h&gt;#include&lt;linux/module.h&gt;#include&lt;linux/kdev_t.h&gt;#include&lt;linux/fs.h&gt;dev_t dev = 0;/*** Module Init function*/static int __init hello_world_init(void){ /*Allocating Major number*/ if((alloc_chrdev_region(&amp;dev, 0, 1, \"MY_Dev\")) &lt;0){ printk(KERN_INFO \"Cannot allocate major number for device 1\\n\"); return -1; } printk(KERN_INFO \"Major = %d Minor = %d \\n\",MAJOR(dev), MINOR(dev)); printk(KERN_INFO \"Kernel Module Inserted Successfully...\\n\"); return 0;}/*** Module exit function*/static void __exit hello_world_exit(void){ unregister_chrdev_region(dev, 1); printk(KERN_INFO \"Kernel Module Removed Successfully...\\n\");} module_init(hello_world_init);module_exit(hello_world_exit); MODULE_LICENSE(\"GPL\");MODULE_AUTHOR(\"Autuor\");MODULE_DESCRIPTION(\"Major and Minor number test dynamic\");MODULE_VERSION(\"1:1.0\");利用如下代码可以查看输出信息：cat /proc/devices | grep \"MY_Dev\"" }, { "title": "VSCode连接远程Linux后Python库加载不完全", "url": "/posts/post20221208/", "categories": "编程", "tags": "Python", "date": "2022-12-08 02:55:06 +0000", "snippet": "一、问题最近在使用VSCode远程连接Linux服务器时，产生了python函数无法索引、不显示分节等问题二、解决1、主要问题VSCode中，远程服务器下的python插件版本没有更新，甚至每次使用vscode登录服务器时都需要重新安装一遍。2、不显示分节如在更新Python插件版本后还无法显示分节，则再更新一下Jupyter的插件版本即可。三、附VSCode的Debug模式还挺好用", "content": "一、问题最近在使用VSCode远程连接Linux服务器时，产生了python函数无法索引、不显示分节等问题二、解决1、主要问题VSCode中，远程服务器下的python插件版本没有更新，甚至每次使用vscode登录服务器时都需要重新安装一遍。2、不显示分节如在更新Python插件版本后还无法显示分节，则再更新一下Jupyter的插件版本即可。三、附VSCode的Debug模式还挺好用" }, { "title": "OpenGL学习（一）", "url": "/posts/post20221207/", "categories": "编程", "tags": "OpenGL", "date": "2022-12-07 01:01:42 +0000", "snippet": "一、前言OpenGL能够实现跨平台的图形显示API调用。其能够使用C++进行编写，效率高，扩展强，跨平台。无论是进行图形显示、引擎开发、驱动开发、显卡开发等等工作都需要进行学习和熟练使用。二、下载1、GLFW下载一个开源的多平台库。官方网站为：https://www.glfw.org/include和lib文件夹是真正要用的。2、GLEW下载一个开源的OpenGL扩展库。官方网站为：http...", "content": "一、前言OpenGL能够实现跨平台的图形显示API调用。其能够使用C++进行编写，效率高，扩展强，跨平台。无论是进行图形显示、引擎开发、驱动开发、显卡开发等等工作都需要进行学习和熟练使用。二、下载1、GLFW下载一个开源的多平台库。官方网站为：https://www.glfw.org/include和lib文件夹是真正要用的。2、GLEW下载一个开源的OpenGL扩展库。官方网站为：https://glew.sourceforge.net/同样的，下载后include和lib文件夹是真正要用的。doc文件夹是网页形式的离线开发文档。3、VS下载安装目前所使用的版本是Visual Studio2017，更新的也可以。三、环境配置1、平台这里我使用的debug平台使用的版本是32（x86）。当然你使用x64也可以的。2、配置1、创建工程后，需要在C/C++的General里的include中，包含GLFW和GLEW的include文件夹。2、在C/C++的Preprocessor第一行添加GLEW_STATIC关键字。3、在Linker的General里的lib中的Additional Library Directories中，添加GLFW和GLEW的lib文件夹。4、在Linker的Input里的Additional Dependencies中，添加glfw3.lib、opengl32.lib、glew32s.lib。四、第一个脚本编写和调试这个脚本作为入门脚本，功能是测试GLEW和GLFW是否配置成功，以及在屏幕上显示一个二维的等边三角。#include &lt;GL/glew.h&gt;#include &lt;GLFW/glfw3.h&gt;#include &lt;iostream&gt;int main(void){\tGLFWwindow* window;\t/* Initialize the library */\tif (!glfwInit())\t\treturn -1;\t/* Create a windowed mode window and its OpenGL context */\twindow = glfwCreateWindow(640, 480, \"Hello World\", NULL, NULL);\tif (!window)\t{\t\tglfwTerminate();\t\treturn -1;\t}\t/* Make the window's context current */\tglfwMakeContextCurrent(window); /* GLEW init and test */\tif (glewInit() != GLEW_OK)\t\tstd::cout &lt;&lt; \"ERROR!\" &lt;&lt; std::endl;\tstd::cout &lt;&lt; glGetString(GL_VERSION) &lt;&lt; std::endl;\tunsigned int a;\tglGenBuffers(1, &amp;a);\t/* Loop until the user closes the window */\twhile (!glfwWindowShouldClose(window))\t{\t\t/* Render here */\t\tglClear(GL_COLOR_BUFFER_BIT);\t\tglBegin(GL_TRIANGLES);\t\tglVertex2f(-0.5f, -0.5f);\t\tglVertex2f( 0.0f, 0.5f);\t\tglVertex2f( 0.5f, -0.5f);\t\tglEnd();\t\t/* Swap front and back buffers */\t\tglfwSwapBuffers(window);\t\t/* Poll for and process events */\t\tglfwPollEvents();\t}\tglfwTerminate();\treturn 0;}debug时，可以在glew.h或glfw3.h文件中进行寻找错误原因。五、参考https://glew.sourceforge.net/https://www.glfw.org/https://www.bilibili.com/video/BV1MJ411u7Bc/https://www.bilibili.com/video/BV11W411N7b9/" }, { "title": "Ubuntu的SSH程序如何脱机运行", "url": "/posts/post20221007/", "categories": "编程", "tags": "Ubuntu", "date": "2022-10-07 07:50:00 +0000", "snippet": "一、问题我们使用SSH连接到远程Linux服务器后，如果网络问题SSH断掉后，Linux上运行的程序就挂掉了。如何保证程序不挂掉呢？使用Screen工具。Screen可以新建多个子窗口（即screen进程），运行在Linux本地。可以通过kill进行终止，SSH断开也不会中断进程。二、安装1、安装ubuntu可以直接通过sudo apt-get install screen进行安装三、使用1...", "content": "一、问题我们使用SSH连接到远程Linux服务器后，如果网络问题SSH断掉后，Linux上运行的程序就挂掉了。如何保证程序不挂掉呢？使用Screen工具。Screen可以新建多个子窗口（即screen进程），运行在Linux本地。可以通过kill进行终止，SSH断开也不会中断进程。二、安装1、安装ubuntu可以直接通过sudo apt-get install screen进行安装三、使用1、查看所有子窗口（screen进程）使用命令：screen -ls可以查看到所有在运行的子窗口（screen进程），包含其进程号和名称。2、新建子窗口（screen进程）使用命令：screen -S new_window新建一个名为new_window的子窗口（即新的screen进程），在此进程下进行操作。3、退出当前子窗口（screen进程）使用快捷键：Ctrl+A+D进行退出当前子窗口（screen进程）（但是不终止进程），会将当前进程挂在后台。4、删除当前子窗口（screen进程）使用命令：exit删除当前子窗口（screen进程）。5、恢复子窗口（screen进程）使用命令：screen -r new_window将new_window窗口（screen进程）从后台恢复至前台。6、清除已经卡死的窗口（screen进程）如果new_window卡死，则使用命令：screen -wipe new_window清除这个子窗口（screen进程）。" }, { "title": "Unity的简单入门", "url": "/posts/post20220925/", "categories": "编程", "tags": "Unity", "date": "2022-09-25 08:04:00 +0000", "snippet": "一、前言Unity能够提供强大的游戏仿真系统，其操作较为简单，容易上手。通过C#语言即可完成游戏开发。可以下载到多种插件进行交互使用，较为方便。二、安装及配置1、Unity安装我们可以在unity官网上下载unity hub个人版，然后再hub中进行unity版本的安装，这样会非常节省时间。https://unity.cn/releases三、通过WASD控制小球移动及通过串口发送字符usi...", "content": "一、前言Unity能够提供强大的游戏仿真系统，其操作较为简单，容易上手。通过C#语言即可完成游戏开发。可以下载到多种插件进行交互使用，较为方便。二、安装及配置1、Unity安装我们可以在unity官网上下载unity hub个人版，然后再hub中进行unity版本的安装，这样会非常节省时间。https://unity.cn/releases三、通过WASD控制小球移动及通过串口发送字符using System.Collections;using System.Collections.Generic;using UnityEngine;using System.IO.Ports;using System.Threading;using System.IO;using UnityEngine.UI;using System;using System.Text;public class First : MonoBehaviour{ //串口通信 public static string portName = \"COM1\";//串口号 public static int baudRate = 9600;//波特率 public static Parity parity = 0;//校验位 public static int dataBit = 8;//数据位 public static StopBits stopBit = (StopBits)1;//停止位 static SerialPort sp = new SerialPort(portName, baudRate, parity, dataBit, stopBit); //打开串口函数 public static void OpenPort(){ ​ sp.ReadTimeout = 1000;​ if(!sp.IsOpen){ ​ sp.Open(); ​ } } //串口发送数据函数 public static void SendData(byte[] dataStr){ ​ sp.Write(dataStr, 0, dataStr.Length);​ Debug.LogWarning(\"send successful\"); } public float movespeed = 5; public GameObject go; //初始化函数 void Start(){​ OpenPort();​ if(sp.IsOpen){​ Debug.LogWarning(\"port open successful\");​ }​ else{​ Debug.LogError(\"port open failed\");​ }​ go = GameObject.Find(\"Sphere\"); } //更新函数 void Update(){​ if (Input.GetKey(KeyCode.W)){​ SendData(Encoding.ASCII.GetBytes(\"123\"));​ go.transform.Translate( 0, 0, movespeed * Time.deltaTime, Space.World);​ }​ if (Input.GetKey(KeyCode.S)){​ go.transform.Translate( 0, 0, movespeed * Time.deltaTime * (-1),Space.World);​ }​ if (Input.GetKey(KeyCode.A)){​ go.transform.Translate(movespeed * Time.deltaTime*(-1), 0, 0, Space.World);​ }​ if (Input.GetKey(KeyCode.D)){​ go.transform.Translate(movespeed * Time.deltaTime, 0, 0, Space.World);​ } } //退出函数 void OnApplicationQuit(){​ if(sp.IsOpen){​ sp.Close();​ }​ Debug.Log(\"OnApplicationQuit\"); }}四、进行导出Unity自带强大的打包功能，可以直接导出为可执行文件，非常简单。在File-&gt;Building Settings中进行配置，然后点击Build后，工程就被打包为一个可执行文件。随后就可以在外面直接运行可执行文件了。" }, { "title": "CUDA编程入门学习", "url": "/posts/post20220924/", "categories": "编程", "tags": "CUDA", "date": "2022-09-24 06:00:00 +0000", "snippet": "一、简介本次学习主要根据《CUDA C编程权威指南》一书来学习，当然我也会在其基础上进行修改。感兴趣的话可以直接翻看原书。书的英文名为《Professional CUDA® C Programming》。主要目的是熟悉GPU与CPU通信、GPU并行思想、简单的环境配置等。二、配置环境1、概述我这里配置的环境是win10下的vscode+SSH+Linux+RTX3090。2、具体操作①win...", "content": "一、简介本次学习主要根据《CUDA C编程权威指南》一书来学习，当然我也会在其基础上进行修改。感兴趣的话可以直接翻看原书。书的英文名为《Professional CUDA® C Programming》。主要目的是熟悉GPU与CPU通信、GPU并行思想、简单的环境配置等。二、配置环境1、概述我这里配置的环境是win10下的vscode+SSH+Linux+RTX3090。2、具体操作①win10下，安装vscode。②vscode中安装SSH。③Linux端安装NVIDIA相关驱动、GCC编译包、nvcc编译包。④使用vscode的SSH连接至Linux端，并新建.cu类型的脚本，进而编译运行。注：本文所使用的脚本类型均为.cu后缀。三、第一个在GPU运行的HelloWorld程序1、熟悉GPU架构2、编写程序①首先新建文件hello.cu，Linux下可以使用touch hello.cu。②这个程序的main函数运行在CPU端，hello()函数则运行在GPU端。③其中GPU是以grid、block、thread几个层级进行组织的。故«&lt;grid,block»&gt;也代表这一层级。如下所示，表示grid开了(1,1,1)的block（也就是一个block），并且在每个block是(6,1,1)的thread。也就是说这个现在共有6个线程并行执行hello函数，当打印到第6个（0，1，2，3，4，5）时，输出线程的打印结果。#include &lt;stdio.h&gt;#include &lt;cuda.h&gt;#include &lt;iostream&gt;using namespace std;__global__ void hello() { if(threadIdx.x == 5) printf(\"Hello World from GPU thread %d\\n\",threadIdx.x);}int main() {​ cout&lt;&lt;\"Hello World from CPU\"&lt;&lt;endl;​ dim3 grid(1, 1, 1);​ dim3 block(6, 1, 1); ​ hello&lt;&lt;&lt;grid, block&gt;&gt;&gt;();​ ​ cudaDeviceSynchronize();​ cudaDeviceReset();​ ​ return 0;}注：GPU端似乎只能使用C语言进行编程，而CPU端则可以正常使用C++进行编程。3、编译执行编译使用nvcc指令，其中sm_86这里的数字86要根据自己的显卡来决定，具体可以在官网上查询。nvcc -arch sm_86 hello.cu -o hello4、输出结果执行编译后的文件，输出结果为：Hello World from CPUHello World from GPU thread 5四、进阶1、进一步熟悉grid和block以下代码来自《CUDA C编程权威指南》一书。此代码则展示了当前checkIndex运行在GPU的哪个坐标，以及整个申请的grid、block大小是多少。#include &lt;cuda_runtime.h&gt;#include &lt;stdio.h&gt;__global__ void checkIndex(void) {​ printf(\"threadIdx:(%d, %d, %d) blockIdx:(%d, %d, %d) blockDim:(%d, %d, %d) \"​ \"gridDim:(%d, %d, %d)\\n\", threadIdx.x, threadIdx.y, threadIdx.z,​ blockIdx.x, blockIdx.y, blockIdx.z, blockDim.x, blockDim.y, blockDim.z,​ gridDim.x,gridDim.y,gridDim.z);}int main(int argc, char **argv) {​ // define total data element​ int nElem = 6;​ // define grid and block structure​ dim3 block (3);​ dim3 grid ((nElem+block.x-1)/block.x);​ // check grid and block dimension from host side​ printf(\"grid.x %d grid.y %d grid.z %d\\n\",grid.x, grid.y, grid.z);​ printf(\"block.x %d block.y %d block.z %d\\n\",block.x, block.y, block.z);​ // check grid and block dimension from device side​ checkIndex &lt;&lt;&lt;grid, block&gt;&gt;&gt; ();​ // reset device before you leave​ cudaDeviceReset();​ return(0);​ }其输出结果为：grid.x 2 grid.y 1 grid.z 1block.x 3 block.y 1 block.z 1threadIdx:(0, 0, 0) blockIdx:(1, 0, 0) blockDim:(3, 1, 1) gridDim:(2, 1, 1)threadIdx:(1, 0, 0) blockIdx:(1, 0, 0) blockDim:(3, 1, 1) gridDim:(2, 1, 1)threadIdx:(2, 0, 0) blockIdx:(1, 0, 0) blockDim:(3, 1, 1) gridDim:(2, 1, 1)threadIdx:(0, 0, 0) blockIdx:(0, 0, 0) blockDim:(3, 1, 1) gridDim:(2, 1, 1)threadIdx:(1, 0, 0) blockIdx:(0, 0, 0) blockDim:(3, 1, 1) gridDim:(2, 1, 1)threadIdx:(2, 0, 0) blockIdx:(0, 0, 0) blockDim:(3, 1, 1) gridDim:(2, 1, 1)2、在GPU设备端与CPU主机之间进行数据的运算和传输①GPU上运行计算程序一般分为如下几个步骤：/***1.DEV端设备初始化。2.Host端变量声明、内存申请、初始化赋值。3.DEV端变量声明、内存申请。4.将Host端代码copy至DEV端。5.调用核函数对存储在DEV内存中的数据进行操作。6.将数据从DEV内存传送回到Host内存。7.释放DEV内存8.释放Host内存***/②首先我们看一段只在本地CPU进行数据运算的例子。重点关注sumArraysOnHost，这里使用的是for循环进行相加运算。#include&lt;stdlib.h&gt;#include&lt;string&gt;#include&lt;time.h&gt;#include&lt;iostream&gt;using namespace std;void sumArraysOnHost(float * A, float *B, float *C, const int N){ for(int idx = 0; idx&lt;N; ++idx) { C[idx] = A[idx] + B[idx]; }}void initialData(float *ip, int size){ time_t t; srand((unsigned) time(&amp;t)); for(int i = 0; i &lt; size; ++i) { ip[i] = (float)(rand() &amp; 0xFF)/10.0f; }}int main(int agrc, char **argv){ int nElem = 1024; size_t nBytes = nElem * sizeof(float); cout&lt;&lt;\"nBytes = \"&lt;&lt;nBytes&lt;&lt;endl; float *h_A, *h_B, *h_C; h_A = (float *)malloc(nBytes); h_B = (float *)malloc(nBytes); h_C = (float *)malloc(nBytes); initialData(h_A, nElem); initialData(h_B, nElem); sumArraysOnHost(h_A, h_B, h_C, nElem); for(int i = 0; i &lt; 10; ++i) { cout&lt;&lt;h_A[i]&lt;&lt;\" + \"&lt;&lt;h_B[i]&lt;&lt;\" = \"&lt;&lt;h_C[i]&lt;&lt;endl; } free(h_A); free(h_B); free(h_C); return 0;}输出为：nBytes = 409613.7 + 13.7 = 27.412.2 + 12.2 = 24.423.3 + 23.3 = 46.610.8 + 10.8 = 21.610.9 + 10.9 = 21.812.9 + 12.9 = 25.84.2 + 4.2 = 8.46.2 + 6.2 = 12.413.2 + 13.2 = 26.412.7 + 12.7 = 25.4③进而，我们可以将sum这个函数变为GPU上可以运行的核函数，并且使用thread的id来作为循环变量来进行求和运算。最后使用checkResult函数来验证GPU运算和CPU运算结果是否一致。如下程序所示：#include &lt;cuda_runtime.h&gt;#include &lt;stdio.h&gt;#include &lt;iostream&gt;using namespace std;void checkResult(float *hostRef, float *gpuRef, const int N) { double epsilon = 1.0E-8; bool match = 1; for (int i=0; i&lt;N; i++) { if (abs(hostRef[i] - gpuRef[i]) &gt; epsilon) { match = 0; printf(\"Arrays do not match!\\n\"); printf(\"host %5.2f gpu %5.2f at current %d\\n\",hostRef[i],gpuRef[i],i); break; } } if (match) printf(\"Arrays match.\\n\\n\");}void initialData(float *ip,int size) { // generate different seed for random number time_t t; srand((unsigned) time(&amp;t)); for (int i=0; i&lt;size; i++) { ip[i] = (float)( rand() &amp; 0xFF )/10.0f; }}void sumArraysOnHost(float *A, float *B, float *C, const int N) { for (int idx=0; idx&lt;N; idx++) C[idx] = A[idx] + B[idx];}__global__ void sumArraysOnGPU(float *A, float *B, float *C) { int i = threadIdx.x; C[i] = A[i] + B[i];}int main(int argc, char **argv) { cout&lt;&lt;\"Device is starting\"&lt;&lt;endl; // set up device int dev = 0; cudaSetDevice(dev); cout&lt;&lt;\"GPU device is #\"&lt;&lt;dev&lt;&lt;endl; // set up data size of vectors int nElem = 32; printf(\"Vector size %d\\n\", nElem); // malloc host memory size_t nBytes = nElem * sizeof(float); float *h_A, *h_B, *hostRef, *gpuRef; h_A = (float *)malloc(nBytes); h_B = (float *)malloc(nBytes); hostRef = (float *)malloc(nBytes); gpuRef = (float *)malloc(nBytes); // initialize data at host side initialData(h_A, nElem); initialData(h_B, nElem); memset(hostRef, 0, nBytes); memset(gpuRef, 0, nBytes); // malloc device global memory float *d_A, *d_B, *d_C; cudaMalloc((float**)&amp;d_A, nBytes); cudaMalloc((float**)&amp;d_B, nBytes); cudaMalloc((float**)&amp;d_C, nBytes); // transfer data from host to device cudaMemcpy(d_A, h_A, nBytes, cudaMemcpyHostToDevice); cudaMemcpy(d_B, h_B, nBytes, cudaMemcpyHostToDevice); // invoke kernel at host side dim3 block (nElem); dim3 grid (nElem/block.x); sumArraysOnGPU&lt;&lt;&lt; grid, block &gt;&gt;&gt;(d_A, d_B, d_C); printf(\"Execution configuration &lt;&lt;&lt;%d, %d&gt;&gt;&gt;\\n\",grid.x,block.x); // copy kernel result back to host side cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost); // add vector at host side for result checks sumArraysOnHost(h_A, h_B, hostRef, nElem); // check device results checkResult(hostRef, gpuRef, nElem); // free device global memory cudaFree(d_A); cudaFree(d_B); cudaFree(d_C); // free host memory free(h_A); free(h_B); free(hostRef); free(gpuRef); return(0);}输出结果为：Device is startingGPU device is #0Vector size 32Execution configuration &lt;&lt;&lt;1, 32&gt;&gt;&gt;Arrays match.3、内存申请、释放、拷贝可以看到上述程序中已经加入很多之前没有用过的函数，例如cudaMemcpy、cudaFree、cudaMalloc等。其实这些函数和C语言中在CPU上申请内存、释放内存、内存拷贝的功能相似，只不过是在cuda上进行内存的申请和释放罢了。cudaMalloc和cudaMemcpy的函数原型分别为：cudaError_t cudaMalloc ( void** devPtr, size_t size )cudaError_t cudaMemcpy ( void* dst, const void* src, size_t count, cudaMemcpyKind kind )//kind包括//➤ cudaMemcpyHostToHost//➤ cudaMemcpyHostToDevice//➤ cudaMemcpyDeviceToHost//➤ cudaMemcpyDeviceToDevice" }, { "title": "2022年4月3款手机横向对比", "url": "/posts/post20220429/", "categories": "生活", "tags": "手机", "date": "2022-04-29 10:22:00 +0000", "snippet": "前言本文着重对比了三款手机，从性能、系统、价格、重量、续航、拍照、屏幕七个方面进行对比。注：以下均为主观评测。手机分别为：华为mate30 5G、红米K50、一加Ace。性能华为mate30 5G版已经是2019年发布的手机了，搭载麒麟990芯片，支持5G信号，性能自然是三者中最弱的。红米K50搭载天玑8100芯片，三者中性能释放最强，开启性能模式后帧率稳定，但功耗增加。一加Ace搭载天玑8...", "content": "前言本文着重对比了三款手机，从性能、系统、价格、重量、续航、拍照、屏幕七个方面进行对比。注：以下均为主观评测。手机分别为：华为mate30 5G、红米K50、一加Ace。性能华为mate30 5G版已经是2019年发布的手机了，搭载麒麟990芯片，支持5G信号，性能自然是三者中最弱的。红米K50搭载天玑8100芯片，三者中性能释放最强，开启性能模式后帧率稳定，但功耗增加。一加Ace搭载天玑8100-MAX芯片，理论上性能不输红米，但实际上却拉跨一些，开启性能模式后依然不如开启性能模式的红米，调度保守。系统华为mate30 5G版搭载鸿蒙2.0系统，底层优化明显，在硬件远不如其他厂商的情况下依然可以做到较快的响应速度，并且杀后台较少，万物互联的生态也比其他厂商好一点，最重要的是系统bug很少，稳定，好评。红米K50搭载miui13系统，系统可玩性很强，会有很多意想不到的惊喜，相较于miui12代少了很多bug，响应是三者最快，好评。一加Ace搭载coloros12.1系统，系统本身中规中矩，游戏盒子做的还不错，其他没什么亮点，相比miui来说稳定一点，不做评价。价格华为mate30 5G 8+128版起售价4999元，后一度跌落至4100元左右，并在麒麟芯片缺货后一度回升到4499元。属于华为旗舰级的一档，水桶机，售价较高，工艺、品控各方面最好。红米K50 8+256 2599元，性价比最高。一加Ace 12+256 2999元，性价比一般。重量华为mate30 5G版，196克，中规中矩，不轻不重。红米K50，201克，稍有一点点重，可以接受。一加Ace，186克，最轻。续航华为mate30 5G版，续航如果不是重度使用，一天一充足矣，4200mAh电池，中规中矩，麒麟芯片功耗很低。40W充电算是三者中最慢的，支持27W无线快充。红米K50，续航最强，5000mAh电池最大，媲美苹果13pro max，天玑8100功耗同样极低。搭载67W充电速度，三者中等。一加Ace，续航最拉跨，4500mAh电池中规中矩。天玑8100-MAX芯片，比红米多了功耗，性能上没有感知到强了多少，反倒是更弱了。150W充电很快，20分钟基本充满，但是掉电同样很快。拍照华为mate30 5G版，毋庸置疑，主摄+长焦+广角，最高3X光变，5X混合光变，没有一个凑数镜头，三者最强，能够基本满足你对手机的所有拍照需求。红米K50，扫码够用。一加Ace，扫码够用。屏幕华为mate30 5G版，三星1080P屏幕，只能说够用。红米K50，三星E5屏幕，2K120HZ，目前最强屏幕。一加Ace，京东方类钻屏幕，1080P，120HZ，中规中矩，但观感可以，看不出与红米的明显差距。总结如果你对拍照有要求，mate30很值，毕竟现在的旗舰机都没有长焦了，mate30本身也是水桶机，各方面不差。如果你对拍照没要求，买红米K50，性价比最高。如果你就只想要150W充电，推荐买realme gt neo 3。" }, { "title": "git学习", "url": "/posts/post20220426/", "categories": "编程", "tags": "Git", "date": "2022-04-26 06:35:05 +0000", "snippet": "简介git为分布式版本控制工具，能够完成自动化的版本合并、拉去、推送、记录等，只需十几个常用命令即可完成这些操作，方便快捷，十分适合企业合作、项目管理等场景使用。git总体分为工作区和版本库，版本库具体又分为stagez（暂存区）和master（主分支）。安装Linux下可以通过这个命令进行安装sudo apt-get install gitWindows下可以直接在官网下载安装包进行安装M...", "content": "简介git为分布式版本控制工具，能够完成自动化的版本合并、拉去、推送、记录等，只需十几个常用命令即可完成这些操作，方便快捷，十分适合企业合作、项目管理等场景使用。git总体分为工作区和版本库，版本库具体又分为stagez（暂存区）和master（主分支）。安装Linux下可以通过这个命令进行安装sudo apt-get install gitWindows下可以直接在官网下载安装包进行安装MacOS下可以通过homebrew进行安装注：下面均通过linux进行操作和演示安装成功后，添加账户名和邮箱git config --global user.email \"xxxxxxxx@xxx.xxx\"git config --global user.name \"penciler-star\"初始化创建一个文件夹git_testmkdir git_test初始化一个仓库git initgit_test文件下会生成一个.git的隐藏文件夹，这样一个仓库就建好了简单添加一个文件到仓库中在git_test文件夹下新建一个test.cpp文件，在linux下可以利用命令touch test.cpp在git_test文件夹下利用git命令完成添加至仓库git add test.cppgit commit test.cpp \"new cpp file\"其中add是将工作区文件上传至暂存区，而commit是将暂存区的文件上传至主分支修改版本库中的文件如将test.cpp修改为如下内容：#include&lt;iostream&gt;using namespace std;int main(){\tcout&lt;&lt;\"hello\"&lt;&lt;endl;\treturn 0;}修改后，利用如下git命令可得到结果，看出此时只是更改了工作区，暂存区和主分支暂无修改git status (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git restore &lt;file&gt;...\" to discard changes in working directory) modified: test.cpp但此时并不知晓更改了什么内容，利用如下git命令，即可得到具体修改的内容git diffdiff --git a/test.cpp b/test.cppindex e69de29..4eedd22 100644--- a/test.cpp+++ b/test.cpp@@ -0,0 +1,7 @@+#include&lt;iostream&gt;+using namespace std;+int main()+{+ cout&lt;&lt;\"hello\"&lt;&lt;endl;+ return 0;+}注：如上两个命令都是查看工作区的内容和状态随后利用如下命令进行提交，并得到返回信息git add test.cppgit commit test.cpp \"output hello\"[master b2190b5] output hello 1 file changed, 7 insertions(+)查看版本刚刚提交了两次至版本库中，那么我们想查看这两次提交，利用如下命令，可得到两次版本修改的结果git logcommit b2190b5e3651ba3eb2132bc86b5799ea9d06c0c9 (HEAD -&gt; master)Author: penciler-star &lt;xxxxx@xxx.com&gt;Date: Sun Apr 10 15:11:03 2022 +0800 output hellocommit ffda9a908310bb247967c3b2e246ce012e2e6e49Author: penciler-star &lt;xxxxx@xxx.com&gt;Date: Sun Apr 10 14:54:28 2022 +0800 new a cpp回退版本我们有时提交的文件有问题，这时需要回退到没有问题的上一个版本，此时利用如下命令，得到返回结果git reset --hard HEAD^HEAD is now at ffda9a9 new a cpp此时，利用git log，已经没有了当前的output hello版本git logcommit ffda9a908310bb247967c3b2e246ce012e2e6e49 (HEAD -&gt; master)Author: penciler-star &lt;xxxxx@xxx.com&gt;Date: Sun Apr 10 14:54:28 2022 +0800\tnew a cpp前进版本假设刚刚只是敲错了命令，但是最新版本已经没了，如何将刚刚的output hello版本寻回？首先我们需要查看所有提交的版本号git reflogb2190b5 (HEAD -&gt; master) HEAD@{0}: reset: moving to b2190b5ffda9a9 HEAD@{1}: reset: moving to HEAD^b2190b5 (HEAD -&gt; master) HEAD@{2}: commit: output helloffda9a9 HEAD@{3}: commit (initial): new a cpp然后利用如下命令进行版本前进：git reset --hard b2190b5HEAD is now at b2190b5 output hellohard后面的参数为output hello的版本号，这样就回到了最新的output hello版本了git logcommit b2190b5e3651ba3eb2132bc86b5799ea9d06c0c9 (HEAD -&gt; master)Author: penciler-star &lt;xxxxx@xxx.com&gt;Date: Sun Apr 10 15:11:03 2022 +0800 output hellocommit ffda9a908310bb247967c3b2e246ce012e2e6e49Author: penciler-star &lt;xxxxx@xxx.com&gt;Date: Sun Apr 10 14:54:28 2022 +0800 new a cpp放弃修改假设刚刚工作区的文件被修改了，但是我们不想要了，则可放弃修改，如下命令可利用版本库中的内容替换工作区的内容git checkout -- test.cpp假设已经被add到暂存区了，但是我们不想要了，则git reset HEAD test.cppgit checkout -- test.cpp假设现在commit到主分支了，但是我们不想要了，则回退版本git reset --hard HEAD^注：假如现在已经pull到远程版本库了，那就完了。删除文件如果你现在想删除某个文件，则：rm test.cppgit rm test.cppgit commit -m \"remove test.cpp\"当然了，如果想撤销，则回退版本如果还没commit，则放弃修改：git checkout -- test.cpp创建分支分支是属于多人协作管理项目时的必备技能，需良好掌握主分支为master，下面开始创建新的分支my_branchgit branch my_branch切换至此分支git switch my_branchSwitched to branch 'my_branch'查看所有分支，当前分支前会呈现一个*git branch master* my_branch合并分支通过如下命令即可实现将两个分支进行合并切换回主分支git switch master分支合并git merge my_branch注：但是有时候合并会引发错误，此时需要在主分支下进行修改引发错误的文件，再提交即可当然，你可以禁用fast forward，进行普通合并git merge --no-ff -m \"no-ff\" my_branch删除分支在合并后，如不需要更多分支，则可选择删除它git branch -d my_branch如果还未合并，则可以强行删除git branch -D my_branch暂存分支如果想暂存现在的工作区，则利用如下命令行git stash如果想恢复工作区，则利用：git stash pop获取分支如果想从远程库获取资源，则需要将远程库的资源克隆到本地，但此时只能获取到主分支mastergit clone xxxx如果想获取其他分支，则需要利用远程的分支来创建本地的分支git checkout -b my_branch origin/my_branch更新分支利用如下命令进行更新本地库git pull推送分支如果想查看远程版本库的信息，则git remote -v进而推送分支git push origin master或者远程版本库上有其他分支，那么可以推送到这个分支git push origin my_branch如果推送失败，则有可能是有冲突，则需要先获取最新的版本，然后再推送git branch --set-upstream-to=origin/my_branch my_branchgit pullgit push origin my_branch图形化界面使用github时，可以利用github desktop进行可视化操作单纯使用git时，可以下载Sourcetree进行操作参考信息https://www.runoob.com/git/git-tutorial.htmlhttps://www.liaoxuefeng.com/wiki/896043488029600http://git-scm.com/" }, { "title": "shell脚本学习", "url": "/posts/study-shell/", "categories": "编程", "tags": "Linux", "date": "2022-04-24 04:34:00 +0000", "snippet": "文件生成、编辑和执行生成和编辑.sh文件touch test.shvi test.sh执行.sh文件. test.shshell脚本简单的输出hello world#! /bin/bashstr=\"hello world!\"echo $str传入变量#! /bin/bash#$1表示传入的第一个参数，$@表示传入的全部参数str=\"hello $1!\"echo $str表达式运算#! /bi...", "content": "文件生成、编辑和执行生成和编辑.sh文件touch test.shvi test.sh执行.sh文件. test.shshell脚本简单的输出hello world#! /bin/bashstr=\"hello world!\"echo $str传入变量#! /bin/bash#$1表示传入的第一个参数，$@表示传入的全部参数str=\"hello $1!\"echo $str表达式运算#! /bin/bashsum=$[ 5 + 7 ]echo $sumif条件判断#! /bin/bashif [ 3 -gt 1 ] &amp;&amp; [ 3 -lt 4 ]then\techo \"OK\";else\techo \"FALSE\";fifor循环#! /bin/bash#第一种sum=0for((i=1;i&lt;=100;i++));do\tsum=$[ $sum + $i ];doneecho $sum#第二种sum=0for i in {1..100}do\tsum=$[ $sum + $i ];doneecho $sum函数#! /bin/bashfunction add(){\tsum=$[ $1 + $2 ];\techo $sum}my_sum=`add 1 3`echo $my_sum其他命令#! /bin/bash#执行后的返回值$?#输入参数的个数$##输入所有的参数$*str=\"/home/test/a.sh\"#删除str的第一个/及其前面的所有内容\"home/test/a.sh\"${str#*/}#删除str的最后一个/及其前面的所有内容\"a.sh\"${str##*/}#删除str的最后一个/及其后面的所有内容\"/home/test\"${str%/*}#删除str的第一个/及其后面的所有内容\"\"${str%%/*}" }, { "title": "Linux下matlab出错", "url": "/posts/post202203292/", "categories": "编程", "tags": "Linux", "date": "2022-03-29 15:59:19 +0000", "snippet": "linux 下 matlab 出错：Execution of script ** as a function is not supported原因分析1.有可能是因为当前matlab目录下存在多个同名文件，造成出错。2.有可能因为当前运行环境中存在某个变量，与文件名或者函数名相同，造成出错。3.windows下编译cpp生成的mexw64文件不能在linux环境下继续使用，造成出错。相对应的...", "content": "linux 下 matlab 出错：Execution of script ** as a function is not supported原因分析1.有可能是因为当前matlab目录下存在多个同名文件，造成出错。2.有可能因为当前运行环境中存在某个变量，与文件名或者函数名相同，造成出错。3.windows下编译cpp生成的mexw64文件不能在linux环境下继续使用，造成出错。相对应的解决方法1.更换同名文件的文件名，使之不重复，可以使用如下命令进行查询： which **.m -all2.更换当前目录中的变量名，或者是文件名。3.在linux环境下，重新使用make命令编译，生成对应的mexa64文件，并添加至matlab的path目录即可。结语大多数网上的帖子提供的是前两个解决方法，但是我是使用第三个方法解决的。同样的报错可能是不同原因引起的，了解报错原因才能更快处理。" }, { "title": "ubuntu20下 Could not load dynamic library 'libcudnn.so.8'; dlerror libcudnn.so.8", "url": "/posts/post202203291/", "categories": "编程", "tags": "Linux", "date": "2022-03-29 14:48:10 +0000", "snippet": "ubuntu20下 Could not load dynamic library ‘libcudnn.so.8’; dlerror: libcudnn.so.8: cannot open share原因分析是由于cudnn没有安装（可能安装了CUDA，但是没安cudnn）解决方法在cudnn官网上注册后，下载对应版本的cudnn，安装即可。由于这里是ubuntu，故不需要使用网上说的复制文件...", "content": "ubuntu20下 Could not load dynamic library ‘libcudnn.so.8’; dlerror: libcudnn.so.8: cannot open share原因分析是由于cudnn没有安装（可能安装了CUDA，但是没安cudnn）解决方法在cudnn官网上注册后，下载对应版本的cudnn，安装即可。由于这里是ubuntu，故不需要使用网上说的复制文件的方法，直接安装.deb即可。当然，复制文件也是一种麻烦的解决方案。安装成功后，问题解决！" }, { "title": "resnet和mobilenet各个模型下载地址", "url": "/posts/post20210420/", "categories": "编程", "tags": "神经网络模型", "date": "2021-01-16 12:42:48 +0000", "snippet": "resnet和mobilenet各个模型下载地址resnetresnet_v1_50_2016_08_28.tar.gzresnet_v1_101_2016_08_28.tar.gzresnet_v1_152_2016_08_28.tar.gzmobilenetmobilenet_v2_1.0_224.tgzmobilenet_v2_0.75_224.tgzmobilenet_v2_0.5_...", "content": "resnet和mobilenet各个模型下载地址resnetresnet_v1_50_2016_08_28.tar.gzresnet_v1_101_2016_08_28.tar.gzresnet_v1_152_2016_08_28.tar.gzmobilenetmobilenet_v2_1.0_224.tgzmobilenet_v2_0.75_224.tgzmobilenet_v2_0.5_224.tgzmobilenet_v2_0.35_224.tgz" }, { "title": "MATLAB调用串口", "url": "/posts/post20210116/", "categories": "编程", "tags": "MATLAB", "date": "2021-01-16 12:42:48 +0000", "snippet": "1、关于串口调用函数更新最新版matlab，现在推荐使用serialport操作，相较于原函数serial()更加简单，创建速度更快。官方链接为：https://ww2.mathworks.cn/help/matlab/ref/serialport.html2、创建一个虚拟串口s = serialport(port,baudrate,Name,Value);其中，port为端口号，baudr...", "content": "1、关于串口调用函数更新最新版matlab，现在推荐使用serialport操作，相较于原函数serial()更加简单，创建速度更快。官方链接为：https://ww2.mathworks.cn/help/matlab/ref/serialport.html2、创建一个虚拟串口s = serialport(port,baudrate,Name,Value);其中，port为端口号，baudrate为波特率，Name可选read、readline、write等等，具体参考链接。3、从串口中读信号s = serialport(\"COM3\",9600,\"Timeout\",5);data = read(s,16,\"uint32\");4、往串口中发数据s = serialport(\"COM3\",9600,\"Timeout\",5);write(s,\"0\",\"string\");5、关闭串口clear s6、注意事项按照我的理解，matlab中创建的串口为虚拟串口，退出即会抹除串口使用痕迹通俗理解就是，matlab的.m程序运行结束后，这个串口发生过的事情不会在串口中留存传统的串口调试助手退出时会保留串口状态所以matlab中使用串口时，要在.m文件运行过程中进行一切操作" }, { "title": "win10本地镜像上传至Docker hub步骤", "url": "/posts/post20210106/", "categories": "编程", "tags": "Docker", "date": "2021-01-06 12:42:48 +0000", "snippet": "1、首先在官网安装最新的docker，然后cmd拉取一个python3.6的纯净包docker pull python:3.6版本可选2、测试是否可以运行helloworld.pydocker run -v C:/Users/psdz/python_test:/user -w /user python:3.6 python helloworld.pyhelloworld.py：print(“...", "content": "1、首先在官网安装最新的docker，然后cmd拉取一个python3.6的纯净包docker pull python:3.6版本可选2、测试是否可以运行helloworld.pydocker run -v C:/Users/psdz/python_test:/user -w /user python:3.6 python helloworld.pyhelloworld.py：print(“hello world!”)我的电脑上，windows目录docker2021最新版必须是C盘3、三个文件Dockerfile:FROM python:3.6COPY . /usr/src/mypythonWORKDIR ./usr/src/mypythonRUN pip install -r requirements.txtCMD [\"python\", \"hello.py\"]requirements.txt:numpyhello.py:import numpy as npa = 1b = 2c = np.add(a,b)print(c)4、构建自己的镜像docker build -t mypython_15、登录自己的hub账号，并将镜像的tag与自己hub上的tag相匹配docker login -u your_namedocker tag mypython_1 your_name/test:my_python6、将自己的镜像push（推到）自己的hub上docker push your_name/test:my_python7、将hub云上的文件pull（下载）到本地docker pull your_name/images:tag8、总结anaconda真好用【狗头】" }, { "title": "DeepLabCut常见错误和解决方法", "url": "/posts/post20201105/", "categories": "编程", "tags": "DeepLabCut", "date": "2020-11-05 11:11:01 +0000", "snippet": "1、deeplabcut import 遇到cannot load backend ‘tkagg’检查matplotlib的版本（按照官方的说法，应该安装3.0.3版本）但是对于我来说并不管用于是我将console关了再开一个就好了。碰运气，有时候会好有时候不会。（不好就再关一次）2、工程路径问题一定要注意，存放DLC的工程要全英文，且首字母尽量不要带n等容易转义的字母。中文会报一些莫名其妙...", "content": "1、deeplabcut import 遇到cannot load backend ‘tkagg’检查matplotlib的版本（按照官方的说法，应该安装3.0.3版本）但是对于我来说并不管用于是我将console关了再开一个就好了。碰运气，有时候会好有时候不会。（不好就再关一次）2、工程路径问题一定要注意，存放DLC的工程要全英文，且首字母尽量不要带n等容易转义的字母。中文会报一些莫名其妙的错误，人都傻了都不知道为啥出错。3、工程名字工程名字不要太长，要全英文。注意，不能太长，太长同样会报一堆错误，注意！" }, { "title": "如何安装PyTorch Geometric", "url": "/posts/post202010312/", "categories": "编程", "tags": "Python", "date": "2020-10-31 13:00:58 +0000", "snippet": "首先，附上geometric官网链接：geometric官网如果你不想看geometric官网，那么往下看：首先进入自己的环境，按顺序输入如下五行（当然需要替换了）：pip install torch-scatter==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-${TORCH}.htmlpip install torc...", "content": "首先，附上geometric官网链接：geometric官网如果你不想看geometric官网，那么往下看：首先进入自己的环境，按顺序输入如下五行（当然需要替换了）：pip install torch-scatter==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-${TORCH}.htmlpip install torch-sparse==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-${TORCH}.htmlpip install torch-cluster==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-${TORCH}.htmlpip install torch-spline-conv==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-${TORCH}.htmlpip install torch-geometric然后即可安装成功。即，如果你是CUDA10.2，torch1.5.0，则输入：pip install torch-scatter==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.5.0.htmlpip install torch-sparse==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.5.0.htmlpip install torch-cluster==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.5.0.htmlpip install torch-spline-conv==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.5.0.htmlpip install torch-geometric安装成功！" }, { "title": "Python3安装包遇到Microsoft Visual C++ 14.0 is required", "url": "/posts/post202010311/", "categories": "编程", "tags": "Python", "date": "2020-10-31 11:10:05 +0000", "snippet": "Python3安装包遇到Microsoft Visual C++ 14.0 is required首先查看具体是哪个包extension，如下图，为kiwisolver。于是到whl网站下载对应的包下载之后Pip安装，即可解决问题。", "content": "Python3安装包遇到Microsoft Visual C++ 14.0 is required首先查看具体是哪个包extension，如下图，为kiwisolver。于是到whl网站下载对应的包下载之后Pip安装，即可解决问题。" }, { "title": "Pytorch下载太慢怎么办——离线安装", "url": "/posts/post20201030/", "categories": "编程", "tags": "Python", "date": "2020-10-30 11:10:05 +0000", "snippet": "离线安装！首先进入网址：pytorch离线满速下载网址下载对应版本的pytorch和torchvision然后pip install 安装成功后继续使用conda在线更新一下即可", "content": "离线安装！首先进入网址：pytorch离线满速下载网址下载对应版本的pytorch和torchvision然后pip install 安装成功后继续使用conda在线更新一下即可" }, { "title": "DeepLabCut教程（二 具体如何使用）", "url": "/posts/post20201015/", "categories": "编程", "tags": "DeepLabCut", "date": "2020-10-15 02:56:11 +0000", "snippet": "DeepLabCut教程（二 具体如何使用）此篇为 二 具体如何使用 在这儿我将使用DLC进行新建工程、标记数据、训练、预测等，这是简化版流程。如果你还不清楚DLC如何安装或者DLC是什么，请查看 一 从零开始安装 ，链接为：DeepLabCut教程（一 从零开始安装）一、使用前言在DLC官网上，已有官方使用教程：https://github.com/DeepLabC...", "content": "DeepLabCut教程（二 具体如何使用）此篇为 二 具体如何使用 在这儿我将使用DLC进行新建工程、标记数据、训练、预测等，这是简化版流程。如果你还不清楚DLC如何安装或者DLC是什么，请查看 一 从零开始安装 ，链接为：DeepLabCut教程（一 从零开始安装）一、使用前言在DLC官网上，已有官方使用教程：https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/UseOverviewGuide.mdDLC官方流程​ 实际上，DLC自从有了自己的GUI后，图形化操作确实非常简单，但因为这个GUI有时会卡BUG，且不利于我们理解DLC背后的代码，故在此我将从新建工程、标记、训练、预测等步骤详细介绍如何使用DLC。二、使用流程1、导入包import deeplabcut​ 当然是先导入dlc的包，如果这一步出错，可能是没有wxPython，在环境中直接pip即可。如果是Spyder，将Graphs显示方式由Inline调整为Qt5。如果是tensorflow的问题，将环境中的tensorflow的uninstall后再安装一下。记得是要安tensorflow-gpu版本的，CPU太慢了（tai man le）。2、新建工程deeplabcut.create_new_project('ProjectName','YourName', ['/usr/FullPath/OfVideo1.avi','/usr/FullPath/OfVideo2.avi','/usr/FullPath/OfVideo1.avi'],copy_videos=True/False,multianimal=True/False)注：这里新建工程后，工程文件夹的路径在这个.py脚本同级的路径下。工程名+作者名不要太长，否则会出一堆错！使用 deeplabcut.create_new_project 函数进行新建工程，参数如上所示，分别是工程名、作者名、视频路径、是否拷贝视频到工程目录中、是否多只动物。其中，DLC2.2目前虽然支持了多只动物的跟踪，但效果一(bu)般(xing)，所以大多数情况下DLC是用来追踪单只动物的。也说不定过两天DLC的多动物追踪也变得十分强大。3、查看配置文件config.yaml注：config.yaml位置在工程目录下为什么这里要特别提到yaml文件，因为这个文件中包含了对整个工程的配置，我们修改其中一些选项，达到对整个工程的控制。讲一些常用的配置选项：project_path: 工程文件夹所在路径，包括文件夹名。bodyparts: 自定义的身体点名称。numframes2pick: 每个视频选择多少张图片作为训练集。dotsize: 追踪点的显示大小。iteration: 当前工程中第几次训练。resnet: 选用resnet的哪个网络。batch_size: 训练的时候batch大小，显存小、GPU运算能力不足时，适当降低batch_size。4、从视频中自动提取训练帧deeplabcut.extract_frames(config_path,mode='automatic',algo='kmeans',crop=True/False)使用 deeplabcut.extract_frames 函数自动从传入的视频中提取训练集。其中参数分别为config.yaml文件路径、是否自动提取、哪种算法提取、是否需要crop裁剪。一般第一个参数传入路径，第二、三个参数不用动，第四个选False。这里可以裁剪但没必要，DLC非常强大，全局特征和局部特征都能有效提取。5、开始标记训练集（humdrum)deeplabcut.label_frames(config_path)使用 deeplabcut.label_frames 函数来进行标记训练集。其中参数为config.yaml文件路径。没错，DLC内部自带标记的GUI，且标记好后自动生成数据集，无需用Labelme等工具标记训练集，也无需自己搞训练集，极大降低了入门门槛。6、检查训练集deeplabcut.check_labels(config_path)使用 deeplabcut.check_labels 函数检查是否将训练集标记完成。7、创建训练环境deeplabcut.create_training_dataset(config_path)使用 deeplabcut.create_training_dataset 进行创建训练环境。这一步如果没有pre_model，则会报错。由于res_net官网访问不了，所以下载预训练模型总会出错。解决方法是在网上搜res_net50或者101或者其他的模型，然后下载解压到Anaconda\\envs\\DLC-GPU\\Lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained 路径下即可。8、开始训练deeplabcut.train_network(config_path)使用 deeplabcut.train_network 训练你的网络。如果你的GPU、CUDA、CUDNN、TensorFlow、训练环境都没问题，则可以开始愉快地开始训练了。GPU能力越强，则训练速度越快，时间越短。推荐RTX2080Ti及以上，如TiTan、Tesla、RTX3080等。如果GPU的显存较小，则适当调小config.yaml中的batch_size。9、评估网络deeplabcut.evaluate_network(config_path,plotting=True)评估网络使用 deeplabcut.evaluate_network。这条函数可以在工程目录下生成评估文件夹，在这个文件夹下可以查看网络一些评估参数的图等。词条语句可以跳过（如果不需要评估网络的话）。10、预测deeplabcut.analyze_videos(config_path,['/fullpath/project/videos/'],videotype='.mp4',save_as_csv=True)​ 使用 deeplabcut.analyze_videos 进行视频的预测。参数分别为：config.yaml文件路径、预测的视频路径、预测的视频格式、是否保存为csv格式。通过这一步生成网络产生的输出，并保存为csv文件，保存在预测视频同级的文件夹下。11、生成带有标记的视频deeplabcut.create_labeled_video(config_path, [`/analysis/project/videos/reachingvideo1.avi','/fullpath/project/videos/reachingvideo2.avi'],filtered=True)使用 deeplabcut.create_labeled_video 函数进行生成带有标记的视频图像。参数为：config.yaml文件路径、原视频名、是否需要滤波。生成的标记视频会保存在原视频同级的目录下。至此，DLC简化版操作完成，可以尝试修改这些函数中的参数，玩出更多可能。三、错误总结这里会不定期更新一些错误及解决方法，敬请期待。错误和解决方案见下连接：错误合集" }, { "title": "DeepLabCut教程（一 从零开始安装）", "url": "/posts/post20201007/", "categories": "编程", "tags": "DeepLabCut", "date": "2020-10-07 09:50:57 +0000", "snippet": "DeepLabCut教程（一 从零开始安装）此篇为 一 从零开始安装 我将尽量详细介绍从零开始安装的整个过程。安装成功后如需查看如何使用，请查看 二 具体如何使用 ，链接为：DeepLabCut教程（二 具体如何使用）一、简述DLC自从问世后，被国内外各类实验室广泛使用，其鲁棒性、实用性远超其他tracking软件或网络。DLC主打动物2D身体点追踪，有预训练网络以及Re...", "content": "DeepLabCut教程（一 从零开始安装）此篇为 一 从零开始安装 我将尽量详细介绍从零开始安装的整个过程。安装成功后如需查看如何使用，请查看 二 具体如何使用 ，链接为：DeepLabCut教程（二 具体如何使用）一、简述DLC自从问世后，被国内外各类实验室广泛使用，其鲁棒性、实用性远超其他tracking软件或网络。DLC主打动物2D身体点追踪，有预训练网络以及ResNet50、101等可选训练网络，支持自定义身体点，流程清晰。甚至有DLC3D的版本，但3D版初期有很多BUG，目前是否修复很多暂不知晓。2019.10，DLC官方发布了2.1版本，终于有了GUI！2020.05，DLC官方发布了DLC2.2版本，支持了多动物追踪功能。由于版本的不断更新，python环境中的版本也有更新，目前已经支持RTX3090，详见11条。二、DLC官方信息DLC官方网址：https://www.mousemotorlab.org/deeplabcut/DLC的Github：https://github.com/DeepLabCut/DeepLabCutDLC的文章链接：2D：https://www.nature.com/articles/s41593-018-0209-y.epdf3D：https://pubmed.ncbi.nlm.nih.gov/31227823/DLC文章一作：Alexander Mathis老哥三、安装流程：其实在DLC的Github上，有详细的安装过程，大家也可以参考（https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/installation.md）。以下是简单的安装流程：1、安装Anaconda，登录Anaconda官网下载即可，安装的时候基本无脑下一步就可以Anaconda官网网址如下：https://www.anaconda.com/products/individual进而安装spyder或pycharm等（可在Anaconda Navigator中一键安装）2、创建conda虚拟环境，打开win+R，输入cmd，打开控制台（有些电脑需要打开anaconda prompt）创建虚拟环境，输入如下命令：conda create -n DLC-GPU python=3.63、查看自己电脑的显卡驱动型号（可以更新驱动https://www.nvidia.cn/Download/index.aspx?lang=cn）使用win+R，输入cmd，打开控制台，输入两行：cd C:\\Program Files\\NVIDIA Corporation\\NVSMInvidia-smi4、查看显卡驱动对应的CUDA版本限制，安装对应版本的CUDA登录CUDA官网下载驱动型号对应版本的CUDA，下载后双击exe无脑下一步安装。https://developer.nvidia.com/cuda-downloads5、下载cuDNN，登录如下网址，根据第4步安装的CUDA版本安装cuDNNhttps://developer.nvidia.com/rdp/cudnn-download（如果之前没登录过，需要注册账号）查找自己的CUDA安装路径，如我的是： C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1，记这个目录为A1。将下载的cuDNN解压，得到一个cuda的文件夹。​ 将下载压缩包 cuda\\bin 目录下的 .dll文件 复制到 A1\\ bin 目录下​ 将下载压缩包 cuda\\include 目录下的 .h文件 复制到 A1\\ include 目录下​ 将下载压缩包 cuda\\lib\\x64 目录下的 .lib文件 复制到 A1\\ lib\\x64 目录下​ 修改环境变量，在系统变量中加入： A1\\lib\\x646、安装conda环境中的tensorflow-gpu、cudatoolkit、cudnn首先需要先进入这个环境，在cmd控制台中输入以下命令以进入刚才第2步新建的conda环境（有些电脑需要输入 conda activate DLC-GPU）：activate DLC-GPU在此环境下需进行conda的换源操作，输入如下命令，将下载conda包的服务器换至国内清华。conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yes之后则需要利用conda命令安装tensorflow-gpu、cudatoolkit、cudnn。输入如下命令以安装这三个包：（网络最好稳定，如果不稳定或未连接网络会报HTTP等错误）conda install cudatoolkit==10.0.130conda install cudnn==7.6.5conda install tensorflow-gpu==1.13.1（tensorflow-gpu也可选择其他版本，官网上说1.0到2.5都可以）注：只要系统上存在python环境中的cudatoolkit和cudnn所兼容的nvidia驱动，则无需要安装完整的CUDA Toolkit（也就是第三、四、五步所介绍的）7、pip换源操作（这一步看自己需求，换源后可基本实现满速下载）pip的换源操作和conda不太一样，如果单次使用pip，使用 -i https://pypi.tuna.tsinghua.edu.cn/simple 也不失为一种选择，如果要批量pip，最好将pip也换源。在C盘目录C:\\Users\\xxx\\pip下面，新建一个文件pip.ini，在ini文件中输入如下语句，即可实现pip永久换源：(如果没有pip这个文件夹，就新建一个）[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple8、安装deeplabcut终于到了这一步了！首先需要先进入对应环境，在cmd控制台中输入以下命令以进入刚才第2步新建的conda环境（有些电脑需要输入 conda activate DLC-GPU）：activate DLC-GPU目前安装deeplabcut时，仅需输入如下命令即可（因为DLC的更新维护比较给力，现在已经很无脑了）：（同样，网络需要保持稳定，也处可手动选择deeplabcut的版本）（下面两条命令二选一即可，如果没有进行第7步可选择这一条）pip install deeplabcut==2.1.8pip install -i https://pypi.tuna.tsinghua.edu.cn/simple deeplabcut9、安装wxPython不知道为啥，deeplabcut里面没有自带wxPython包，不安装又会报错，故pip安装一个。同样地，在cmd窗口下激活环境（有些电脑需要输入 conda activate DLC-GPU）：activate DLC-GPU使用pip安装默认版本的wxPython（有时候会报错，故推荐4.0.7）：pip install wxPython==4.0.710、测试安装是否成功新打开一个cmd控制台，输入activate DLC-GPU激活环境（可能是conda activate DLC-GPU，也可能必须要进入anaconda prompt才可以）输入如下命令，如果没有报错则安装成功。pythonimport deeplabcut11、版本更新如果你拥有了RTX3090显卡，那么需要安装CUDA11、tf2.5的版本。目前推荐的列表为：tensorflow-gpu=2.5cudatoolkit=11.3.1cudnn=8.2.1deeplabcut=2.2rc3四、一些错误：DLC毕竟还是一个开源包，一些问题还是很多，在官网github页面下也已经有非常非常多的问题和解决方案，在这里我也会不定期更新一些常见错误：错误合集见链接：错误合集" }, { "title": "Win10自行安装Pytorch", "url": "/posts/post20201004/", "categories": "编程", "tags": "Python", "date": "2020-10-04 05:40:05 +0000", "snippet": "Win10自行安装Pytorch1、首先安装Anaconda + Pycharm，这里不做详细解释（Pycharm自行考虑是否需要安装，可用其他软件代替，如spyder）Anaconda安装网址 https://www.anaconda.com/products/individualPycharm 安装网址 https://www.jetbrains.com（现在在Anaconda安装之后现...", "content": "Win10自行安装Pytorch1、首先安装Anaconda + Pycharm，这里不做详细解释（Pycharm自行考虑是否需要安装，可用其他软件代替，如spyder）Anaconda安装网址 https://www.anaconda.com/products/individualPycharm 安装网址 https://www.jetbrains.com（现在在Anaconda安装之后现在可以直接勾选安装pycharm，无需在官网下载，如果使用软件破解了Pycharm，则无法访问Pycharm官网）2、查看自己电脑的显卡驱动型号（可以更新驱动https://www.nvidia.cn/Download/index.aspx?lang=cn）使用win+R，输入cmd，打开控制台，输入两行：cd C:\\Program Files\\NVIDIA Corporation\\NVSMInvidia-smi3、查看显卡驱动对应的CUDA版本限制，安装对应版本的CUDA登录CUDA官网下载驱动型号对应版本的CUDAhttps://developer.nvidia.com/cuda-downloads4、安装cuDNNhttps://developer.nvidia.com/rdp/cudnn-download（如果之前没登录过，需要注册账号）查找自己的CUDA安装路径，如我的是： C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1，记这个目录为A1。将下载的cuDNN解压，得到一个cuda的文件夹。将下载压缩包 cuda\\bin 目录下的.dll文件复制到 A1\\ bin 目录下将下载压缩包 cuda\\include 目录下的.h文件复制到 A1\\ include 目录下将下载压缩包 cuda\\lib\\x64 目录下的.lib文件复制到 A1\\ lib\\x64 目录下修改环境变量，在系统变量中加入： A1\\lib\\x645、登录Pytorch官网下载对应CUDA版本的Pytorchhttps://pytorch.org/此处可能需要先新建一个conda环境，并换国内镜像源，可满速下载。6、安装结束后，在对应环境的Python解释器中输入如下命令，如果正常输出，就说明安装成功import torchtorch.__version__ #查看torch是否可用torch.cuda.is_available() #查看GPU是否可用输出：'1.6.0'True" }, { "title": "openCV的SIFT()不能用", "url": "/posts/post201911022/", "categories": "编程", "tags": "OpenCV", "date": "2019-11-02 08:22:00 +0000", "snippet": "OpenCV的SIFT()不能用OpenCV的SIFT()不能用，版权问题，只需回退OpenCV的版本即可pip uninstall opencv-pythonpip uninstall opencv-contrib-pythonpip install opencv_python==3.4.2.16pip install opencv-contrib-python==3.4.2.16然后再打...", "content": "OpenCV的SIFT()不能用OpenCV的SIFT()不能用，版权问题，只需回退OpenCV的版本即可pip uninstall opencv-pythonpip uninstall opencv-contrib-pythonpip install opencv_python==3.4.2.16pip install opencv-contrib-python==3.4.2.16然后再打开一次python环境即可运行import cv2sift = cv2.SIFT()" }, { "title": "OpenCV出现(-215:Assertion failed) nimages > 0 && nimages", "url": "/posts/post201911021/", "categories": "编程", "tags": "OpenCV", "date": "2019-11-02 02:11:00 +0000", "snippet": "OpenCV出现(-215:Assertion failed) nimages &gt; 0 &amp;&amp; nimagesPython下的opencv进行图像处理报错import numpy as npimport cv2import glob# termination criteriacriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRIT...", "content": "OpenCV出现(-215:Assertion failed) nimages &gt; 0 &amp;&amp; nimagesPython下的opencv进行图像处理报错import numpy as npimport cv2import glob# termination criteriacriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)objp = np.zeros((5*3,3), np.float32)objp[:,:2] = np.mgrid[0:5,0:3].T.reshape(-1,2)# Arrays to store object points and image points from all the images.objpoints = [] # 3d point in real world spaceimgpoints = [] # 2d points in image plane.images = glob.glob('E:/3Drebuild/newfolder/newfolder/*.jpg')for fname in images: img = cv2.imread(fname) gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # Find the chess board corners ret, corners = cv2.findChessboardCorners(gray, (5,3),None) # If found, add object points, image points (after refining them) if ret == True: objpoints.append(objp) corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria) imgpoints.append(corners2) # Draw and display the corners img = cv2.drawChessboardCorners(img, (5,3), corners2,ret) cv2.imshow('img',img) cv2.waitKey(500)cv2.destroyAllWindows()ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)报错如下：error: OpenCV(3.4.7) C:\\projects\\opencv-python\\opencv\\modules\\calib3d\\src\\calibration.cpp:3120: error: (-215:Assertion failed) nimages &gt; 0 &amp;&amp; nimages == (int)imagePoints1.total() &amp;&amp; (!imgPtMat2 || nimages == (int)imagePoints2.total()) in function 'cv::collectCalibrationData'出错原因及解决方案：objp = np.zeros((5*3,3), np.float32)objp[:,:2] = np.mgrid[0:5,0:3].T.reshape(-1,2)一般是由于这两行的问题，记住修改即可" }, { "title": "Windows下安装Python+PCL", "url": "/posts/post20191024/", "categories": "编程", "tags": "Python", "date": "2019-10-24 01:01:00 +0000", "snippet": "Windows下安装Python+PCL先安装python3.6.3PCL不好装，发现有个库叫python-pcl，装了一下午没装上。在将要放弃的时候忽然发现还有个库叫pclpy。pclpy安装步骤win+R，输入cmd，打开控制台，输入pip install pclpy打开pythonpython在python中输入import pclpyfrom pclpy import pcldone！", "content": "Windows下安装Python+PCL先安装python3.6.3PCL不好装，发现有个库叫python-pcl，装了一下午没装上。在将要放弃的时候忽然发现还有个库叫pclpy。pclpy安装步骤win+R，输入cmd，打开控制台，输入pip install pclpy打开pythonpython在python中输入import pclpyfrom pclpy import pcldone！" }, { "title": "感谢关注！", "url": "/posts/hello-world/", "categories": "随笔", "tags": "生活", "date": "2019-03-26 02:34:00 +0000", "snippet": "持续更新中……#include&lt;iostream&gt;int main(){\tstd::cout&lt;&lt;\"hello world!\"&lt;&lt;std::endl;\treturn 0;}Tomorrow will be better", "content": "持续更新中……#include&lt;iostream&gt;int main(){\tstd::cout&lt;&lt;\"hello world!\"&lt;&lt;std::endl;\treturn 0;}Tomorrow will be better" } ]
